{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10909911,"sourceType":"datasetVersion","datasetId":6781707}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tesla Stock Price Forecasting: LSTM vs RNN Comparison\n\nThis notebook implements a comparative analysis of Long Short-Term Memory (LSTM) networks and Simple Recurrent Neural Networks (RNN) for predicting Tesla stock prices. The analysis includes data preprocessing, feature engineering, model training, evaluation, and forecasting.\n\nThe goal is to determine which model architecture performs better for this specific time series forecasting task and generate 30-day forecasts for Tesla stock.","metadata":{}},{"cell_type":"markdown","source":"## Libraries and Dependencies\n\nThis analysis uses the following libraries:\n\n- **pandas & numpy**: For data manipulation and numerical operations\n- **seaborn & matplotlib**: For data visualization and plotting\n- **sklearn**: For data preprocessing, model evaluation metrics, and train-test splitting\n- **tensorflow.keras**: For building and training deep learning models\n- **time**: For measuring and comparing model training times\n- **matplotlib.dates**: For handling date formatting in plots","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Input, SimpleRNN, Bidirectional\nimport tensorflow as tf\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport time\nimport matplotlib.dates as mdates\nimport random\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:35.086252Z","iopub.execute_input":"2025-04-26T17:17:35.086846Z","iopub.status.idle":"2025-04-26T17:17:38.831252Z","shell.execute_reply.started":"2025-04-26T17:17:35.086821Z","shell.execute_reply":"2025-04-26T17:17:38.830597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preparation\n\nThe data preparation process includes:\n\n1. **Loading the dataset**: Reading Tesla stock price data from CSV\n2. **Preprocessing**: Converting data types, handling dates, and setting up the index\n3. **Feature engineering**: \n   - Computing percentage changes in closing price\n   - Calculating moving averages\n4. **Sequence creation**: Converting time series data into supervised learning format\n   - Each sequence of length 120 days becomes an input (X)\n   - The next day becomes the target (y)\n5. **Scaling**: Normalizing the data using MinMaxScaler to improve model training\n6. **Train-test-validation split**: Dividing data into training, validation, and test sets","metadata":{}},{"cell_type":"code","source":"# -------------- Set Random Seeds --------------\nseed = 42\ndef set_seeds(seed_value=seed):\n    \"\"\"Set seeds for reproducibility across all libraries\"\"\"\n    # Python built-in random module\n    random.seed(seed_value)\n    \n    # NumPy\n    np.random.seed(seed_value)\n    \n    # TensorFlow\n    tf.random.set_seed(seed_value)\n    \n    # Set Python hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    # Configure TensorFlow for deterministic operations\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    \n    # Configure TensorFlow session\n    try:\n        tf.config.experimental.enable_op_determinism()\n    except:\n        # Older TensorFlow versions might not have this\n        print(\"TensorFlow enable_op_determinism not available in this version\")\n    \n    # For TensorFlow 2.x compatibility - don't use set_session which is deprecated\n    if hasattr(tf, 'compat') and hasattr(tf.compat, 'v1'):\n        # Try to set up the TF 1.x style configs (for older TF 2.x versions)\n        try:\n            tf.compat.v1.set_random_seed(seed_value)\n            session_conf = tf.compat.v1.ConfigProto(\n                intra_op_parallelism_threads=1,\n                inter_op_parallelism_threads=1\n            )\n            # Only set session if the function exists\n            if hasattr(tf.compat.v1.keras.backend, 'set_session'):\n                sess = tf.compat.v1.Session(config=session_conf)\n                tf.compat.v1.keras.backend.set_session(sess)\n        except Exception as e:\n            print(f\"TF 1.x compatibility mode setting failed: {e}\")\n    \n    print(f\"All seeds set to {seed_value} for reproducibility\")\n\n# Set seeds at the very beginning\n# set_seeds(seed)\n\n\n# -------------- Data Loading Functions --------------\ndef load_data(file_path):\n    \"\"\"Load and preprocess the dataset\"\"\"\n    # Mount Google Drive if in Colab\n    try:\n        from google.colab import drive\n        drive.mount(\"/content/drive\", force_remount=True)\n        print(\"Google Drive mounted successfully\")\n    except:\n        print(\"Not running in Google Colab or drive already mounted\")\n\n    # Load data\n    df = pd.read_csv(file_path)\n    df = df.drop([0, 1], axis=0).reset_index(drop=True)\n\n    # Convert columns to float\n    for col in df.columns[1:]:\n        df[col] = df[col].apply(lambda x: float(x))\n\n    # Rename columns to lowercase\n    df.columns = df.columns.str.lower()\n\n    # Fix date column\n    df['date'] = pd.to_datetime(df['price'])\n    df.drop(['price'], inplace=True, axis=1)\n\n    # Set date as index\n    df.set_index('date', inplace=True)\n\n    return df\n\n# -------------- Feature Engineering --------------\ndef calculate_pct_change(df):\n    \"\"\"Calculate percentage change in closing price\"\"\"\n    pct_change = []\n    pct_change.append(0)\n    for i in range(1, df.shape[0]):\n        value = (df['close'][i] - df['close'][i-1])*100/df['close'][i-1]\n        pct_change.append(value)\n\n    return np.array(pct_change)\n\ndef calculate_moving_average(data, n_steps=15):\n    \"\"\"Calculate moving average of a time series\"\"\"\n    ma = [0] * n_steps\n    for i in range(n_steps, data.shape[0]):\n        ma_val = np.mean(data.iloc[i - n_steps + 1: i+1])\n        ma.append(ma_val)\n    return np.array(ma)\n\n\n# Function to calculate RSI\ndef calculate_rsi(data, window=14):\n    \"\"\"Calculate Relative Strength Index (RSI)\"\"\"\n    # Calculate price changes\n    delta = data.diff()\n    \n    # Create gain (up) and loss (down) series\n    gain = delta.clip(lower=0)\n    loss = -delta.clip(upper=0)\n    \n    # Calculate average gain and average loss\n    avg_gain = gain.rolling(window=window).mean()\n    avg_loss = loss.rolling(window=window).mean()\n    \n    # Calculate relative strength\n    rs = avg_gain / avg_loss\n    \n    # Calculate RSI\n    rsi = 100 - (100 / (1 + rs))\n    \n    # Fill NaN values\n    rsi[:window] = 50  # Fill initial NaN values with neutral RSI\n    \n    return rsi\n\n\n# -------------- Sequence Creation --------------\ndef create_sequences(data, seq_length):\n    \"\"\"Create sequences for LSTM model\"\"\"\n    X = []\n    y = []\n    for i in range(len(data) - seq_length):\n        X.append(data[i:i+seq_length])  # Shape = (batch size, sequence length, features)\n        y.append(data[i+seq_length])    # Next row as prediction target\n    return np.array(X), np.array(y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:38.832470Z","iopub.execute_input":"2025-04-26T17:17:38.832940Z","iopub.status.idle":"2025-04-26T17:17:38.845992Z","shell.execute_reply.started":"2025-04-26T17:17:38.832919Z","shell.execute_reply":"2025-04-26T17:17:38.845287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Architecture\n\n### LSTM Model\n\nLong Short-Term Memory networks are specialized RNNs designed to capture long-term dependencies in sequential data:\n","metadata":{}},{"cell_type":"code","source":"\n# -------------- Model Building --------------\ndef build_lstm_model(input_shape, units=100):\n    \"\"\"Build LSTM model architecture\"\"\"\n    set_seeds(seed)\n    model = Sequential()\n    model.add(Input(shape=input_shape))\n    # model.add((LSTM(units=units, return_sequences=True)))\n    # model.add(Dropout(0.2))\n    model.add(LSTM(units=units, return_sequences=False))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=input_shape[1]))\n\n    model.compile(optimizer='Adam', loss='mean_squared_error')\n    return model\n\ndef build_rnn_model(input_shape, units=100):\n    \"\"\"Build Vanilla RNN model architecture with the same structure as LSTM\"\"\"\n    set_seeds(seed)\n    model = Sequential()\n    model.add(Input(shape=input_shape))\n    # model.add(SimpleRNN(units=units, return_sequences=True))\n    # model.add(Dropout(0.2))\n    model.add(SimpleRNN(units=units, return_sequences=False))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=input_shape[1]))\n\n    model.compile(optimizer='Adam', loss='mean_squared_error')\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:38.847041Z","iopub.execute_input":"2025-04-26T17:17:38.847337Z","iopub.status.idle":"2025-04-26T17:17:38.873441Z","shell.execute_reply.started":"2025-04-26T17:17:38.847312Z","shell.execute_reply":"2025-04-26T17:17:38.872611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. Forecasting Methodology\n\n```markdown\n## Forecasting Methodology\n\nThis analysis implements recursive multi-step forecasting:\n\n1. Start with the last known sequence of actual data (120 days)\n2. Make a prediction for the next day (t+1)\n3. Shift the window forward by removing the oldest day (t-120)\n4. Add the new prediction to the end of the window\n5. Use this updated window to predict the next day (t+2)\n6. Repeat steps 3-5 for the desired forecast horizon (30 days)\n\nThis approach allows for generating predictions beyond the available data, but can suffer from error accumulation over longer horizons as each prediction builds on previous predictions.","metadata":{}},{"cell_type":"code","source":"# -------------- Forecasting Function --------------\ndef forecast_future(model, last_sequence, scaler, days_to_predict, seq_length, feature_count, start_date):\n    \"\"\"Generate future forecasts based on the model\"\"\"\n    # Create array to store predictions\n    forecasted_values = np.empty((days_to_predict, feature_count))\n\n    # Create window for recursive prediction\n    window = np.empty((days_to_predict, seq_length, feature_count))\n\n    # Initial window from last sequence of actual data\n    window[0, :, :] = last_sequence\n\n    # First prediction\n    to_predict = window[0, :, :].reshape(1, seq_length, feature_count)\n    forecasted_values[0, :] = model.predict(to_predict, verbose=False)\n\n    # Subsequent predictions\n    for i in range(1, days_to_predict):\n        window[i, :-1, :] = window[i-1, 1:, :]  # Remove first row of previous window\n        window[i, -1, :] = forecasted_values[i-1, :]  # Add previous prediction\n        to_predict = window[i, :, :].reshape(1, seq_length, feature_count)\n        forecasted_values[i, :] = model.predict(to_predict, verbose=False)\n\n    # Inverse transform scaled predictions\n    forecasted_values = scaler.inverse_transform(forecasted_values)\n\n    # Create DataFrame with date index\n    forecast_index = pd.date_range(start=start_date, periods=days_to_predict, freq='B')\n    forecasted_df = pd.DataFrame(forecasted_values, index=forecast_index)\n\n    return forecasted_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:38.874987Z","iopub.execute_input":"2025-04-26T17:17:38.875450Z","iopub.status.idle":"2025-04-26T17:17:38.888069Z","shell.execute_reply.started":"2025-04-26T17:17:38.875431Z","shell.execute_reply":"2025-04-26T17:17:38.887209Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation Metrics\n\nThe models are evaluated using multiple performance metrics:\n\n- **Mean Squared Error (MSE)**: Average of squared differences between predictions and actual values\n- **Root Mean Squared Error (RMSE)**: Square root of MSE, providing error in the same units as the target variable\n- **Mean Absolute Error (MAE)**: Average of absolute differences between predictions and actual values\n- **R² Score**: Proportion of variance in the dependent variable explained by the model\n- **Mean Absolute Percentage Error (MAPE)**: Average percentage difference between predictions and actual values\n\nThese metrics provide a comprehensive view of model performance from different perspectives.","metadata":{}},{"cell_type":"code","source":"\n\n# -------------- Performance Metrics --------------\ndef calculate_metrics(y_true, y_pred):\n    \"\"\"Calculate various performance metrics\"\"\"\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n\n    # Calculate MAPE (Mean Absolute Percentage Error)\n    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\n    return {\n        'MSE': mse,\n        'RMSE': rmse,\n        'MAE': mae,\n        'R²': r2,\n        'MAPE (%)': mape\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:38.888891Z","iopub.execute_input":"2025-04-26T17:17:38.889141Z","iopub.status.idle":"2025-04-26T17:17:38.911876Z","shell.execute_reply.started":"2025-04-26T17:17:38.889116Z","shell.execute_reply":"2025-04-26T17:17:38.911010Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization Functions\n\nMultiple visualization functions help analyze and compare the models:\n\n1. **Data Exploration**:\n   - `plot_percentage_change()`: Visualizes daily price changes and their distribution\n   - `plot_stock_with_ma()`: Shows stock price with moving average and volume\n   - `plot_volatility_analysis()`: Examines price volatility over time\n   - `plot_candlestick_chart()`: Traditional OHLC financial chart\n\n2. **Model Comparison**:\n   - `plot_model_comparison()`: Compares predictions against actual prices\n   - `plot_error_comparison()`: Analyzes prediction errors for both models\n   - `plot_close_predictions_detail()`: Detailed view of recent predictions\n   - `plot_forecast_comparison()`: Compares future forecasts from both models\n   - `plot_training_history()`: Visualizes training and validation loss curves\n   - `compare_model_metrics()`: Side-by-side comparison of performance metrics","metadata":{}},{"cell_type":"code","source":"\n\n# -------------- Visualization Functions --------------\ndef plot_percentage_change(df_index, pct_change):\n    \"\"\"Plot percentage change in closing price\"\"\"\n    plt.figure(figsize=(20, 6))\n    sns.lineplot(x=df_index, y=pct_change)\n    plt.xlabel('Year')\n    plt.ylabel('Percentage Change (%)')\n    plt.title('Percentage Change in Tesla Stock Price')\n    plt.grid(True)\n    plt.show()\n\n    # Plot distribution of percentage changes\n    plt.figure(figsize=(12, 6))\n    sns.histplot(x=pct_change, bins=100, kde=True)\n    plt.title(f\"Distribution of Percentage Changes (Mean: {pct_change.mean():.4f}%)\")\n    plt.axvline(pct_change.mean(), color='r', linestyle='--')\n    plt.show()\n\ndef plot_stock_with_ma(df, ma, n_steps):\n    \"\"\"Plot stock price with moving average and volume\"\"\"\n    plt.figure(figsize=(20, 6))\n    plt.plot(df.index, df['close'], 'b-', label='Close Price')\n    plt.bar(df.index, df['volume']/3e6, alpha=0.3, label='Volume (scaled)')\n    plt.plot(df.index[n_steps:], ma[n_steps:], 'r', label=f'{n_steps}-day Moving Avg')\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Price ($)\")\n    plt.title(\"Tesla Stock Price with Moving Average and Volume\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_model_comparison(df, lstm_pred, rnn_pred, lstm_forecast=None, rnn_forecast=None):\n    \"\"\"Plot LSTM vs RNN predictions and forecasts\"\"\"\n    plt.figure(figsize=(20, 10))\n\n    # Plot actual values\n    plt.plot(df.index, df['close'], 'k-', label='Actual', linewidth=2)\n\n    # Plot LSTM and RNN predictions\n    plt.plot(lstm_pred.index, lstm_pred['close'], 'b-', label='LSTM Predicted', alpha=0.8)\n    plt.plot(rnn_pred.index, rnn_pred['close'], 'g-', label='RNN Predicted', alpha=0.8)\n\n    # Plot forecasts if provided\n    if lstm_forecast is not None and rnn_forecast is not None:\n        plt.axvline(x=lstm_forecast.index[0], color='k', linestyle='--', label='Forecast Start')\n        plt.plot(lstm_forecast.index, lstm_forecast['close'], 'b--', label='LSTM Forecast')\n        plt.plot(rnn_forecast.index, rnn_forecast['close'], 'g--', label='RNN Forecast')\n\n    plt.grid(True)\n    plt.xlabel('Date')\n    plt.ylabel('Price ($)')\n    plt.title('Tesla Stock Price: LSTM vs RNN Comparison')\n    plt.legend()\n    plt.show()\n\ndef plot_error_comparison(df, lstm_pred, rnn_pred):\n    \"\"\"Plot error comparison between LSTM and RNN\"\"\"\n    # Calculate errors\n    lstm_error = lstm_pred['close'] - df.loc[lstm_pred.index, 'close']\n    rnn_error = rnn_pred['close'] - df.loc[rnn_pred.index, 'close']\n\n    plt.figure(figsize=(20, 12))\n\n    # Plot 1: Absolute errors\n    plt.subplot(2, 1, 1)\n    plt.plot(lstm_pred.index, np.abs(lstm_error), 'b-', label='LSTM |Error|')\n    plt.plot(rnn_pred.index, np.abs(rnn_error), 'g-', label='RNN |Error|')\n    plt.title('Absolute Prediction Errors: LSTM vs RNN')\n    plt.ylabel('Absolute Error ($)')\n    plt.legend()\n    plt.grid(True)\n\n    # Plot 2: Error distributions\n    plt.subplot(2, 1, 2)\n    plt.hist(lstm_error, bins=50, alpha=0.5, label='LSTM Error', color='blue')\n    plt.hist(rnn_error, bins=50, alpha=0.5, label='RNN Error', color='green')\n    plt.axvline(lstm_error.mean(), color='blue', linestyle='--', label=f'LSTM Mean Error: {lstm_error.mean():.2f}')\n    plt.axvline(rnn_error.mean(), color='green', linestyle='--', label=f'RNN Mean Error: {rnn_error.mean():.2f}')\n    plt.title('Error Distribution: LSTM vs RNN')\n    plt.xlabel('Error ($)')\n    plt.ylabel('Frequency')\n    plt.legend()\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_close_predictions_detail(df, lstm_pred, rnn_pred, window_size=30):\n    \"\"\"Plot detailed close price predictions for the last window_size days\"\"\"\n    # Get the last window_size days\n    last_days = df.index[-window_size:]\n\n    # Filter predictions for those days\n    lstm_last = lstm_pred.loc[lstm_pred.index.isin(last_days)]\n    rnn_last = rnn_pred.loc[rnn_pred.index.isin(last_days)]\n    actual_last = df.loc[last_days]\n\n    plt.figure(figsize=(20, 8))\n    plt.plot(actual_last.index, actual_last['close'], 'ko-', label='Actual', linewidth=2)\n    plt.plot(lstm_last.index, lstm_last['close'], 'bs-', label='LSTM', markersize=8)\n    plt.plot(rnn_last.index, rnn_last['close'], 'g^-', label='RNN', markersize=8)\n\n    plt.grid(True)\n    plt.xlabel('Date')\n    plt.ylabel('Price ($)')\n    plt.title(f'Detailed Comparison of Last {window_size} Days Predictions')\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\ndef plot_forecast_comparison(lstm_forecast, rnn_forecast):\n    \"\"\"Plot detailed comparison of LSTM and RNN forecasts\"\"\"\n    plt.figure(figsize=(20, 8))\n\n    plt.plot(lstm_forecast.index, lstm_forecast['close'], 'b-o', label='LSTM Forecast')\n    plt.plot(rnn_forecast.index, rnn_forecast['close'], 'g-^', label='RNN Forecast')\n\n    # Calculate the difference between forecasts\n    diff = lstm_forecast['close'] - rnn_forecast['close']\n\n    # Plot the difference as a bar chart on a secondary axis\n    ax1 = plt.gca()\n    ax2 = ax1.twinx()\n    ax2.bar(lstm_forecast.index, diff, alpha=0.3, color='r', label='LSTM - RNN')\n    ax2.set_ylabel('Difference ($)')\n\n    # Add grid and labels\n    plt.grid(True)\n    ax1.set_xlabel('Date')\n    ax1.set_ylabel('Price ($)')\n    plt.title('Forecast Comparison: LSTM vs RNN')\n\n    # Combine legends from both axes\n    lines1, labels1 = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')\n\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\ndef plot_training_history(lstm_history, rnn_history):\n    \"\"\"Plot training and validation loss history for both models\"\"\"\n    plt.figure(figsize=(15, 10))\n\n    # Plot training losses\n    plt.subplot(2, 1, 1)\n    plt.plot(lstm_history.history['loss'], label='LSTM Training Loss')\n    plt.plot(rnn_history.history['loss'], label='RNN Training Loss')\n    plt.title('Training Loss: LSTM vs RNN')\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Squared Error')\n    plt.legend()\n    plt.grid(True)\n    plt.yscale('log')  # Log scale often helps visualize the convergence better\n\n    # Plot validation losses\n    plt.subplot(2, 1, 2)\n    plt.plot(lstm_history.history['val_loss'], label='LSTM Validation Loss')\n    plt.plot(rnn_history.history['val_loss'], label='RNN Validation Loss')\n    plt.title('Validation Loss: LSTM vs RNN')\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Squared Error')\n    plt.legend()\n    plt.grid(True)\n    plt.yscale('log')\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_individual_training_history(lstm_history, rnn_history):\n    \"\"\"Plot separate training and validation loss charts for each model\"\"\"\n    # LSTM Loss Plot\n    plt.figure(figsize=(15, 6))\n    plt.plot(lstm_history.history['loss'], label='Training Loss')\n    plt.plot(lstm_history.history['val_loss'], label='Validation Loss')\n    plt.title('LSTM Model: Training vs Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Squared Error')\n    plt.legend()\n    plt.grid(True)\n    plt.yscale('log')\n    plt.tight_layout()\n    plt.show()\n\n    # RNN Loss Plot\n    plt.figure(figsize=(15, 6))\n    plt.plot(rnn_history.history['loss'], label='Training Loss')\n    plt.plot(rnn_history.history['val_loss'], label='Validation Loss')\n    plt.title('RNN Model: Training vs Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Squared Error')\n    plt.legend()\n    plt.grid(True)\n    plt.yscale('log')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_volatility_analysis(df):\n    \"\"\"Plot volatility analysis over time\"\"\"\n    # Calculate rolling standard deviation (volatility)\n    volatility = df['close'].rolling(window=20).std()\n\n    plt.figure(figsize=(20, 10))\n\n    # Plot 1: Stock Price\n    plt.subplot(2, 1, 1)\n    plt.plot(df.index, df['close'], label='Close Price')\n    plt.title('Tesla Stock Price')\n    plt.ylabel('Price ($)')\n    plt.legend()\n    plt.grid(True)\n\n    # Plot 2: Volatility\n    plt.subplot(2, 1, 2)\n    plt.plot(df.index, volatility, color='red', label='20-day Volatility')\n    plt.title('Tesla Stock Price Volatility (20-day Rolling Std)')\n    plt.xlabel('Date')\n    plt.ylabel('Volatility ($)')\n    plt.legend()\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_candlestick_chart(df, days=90):\n    \"\"\"Plot candlestick chart for the last n days\"\"\"\n    # Get last n days of data\n    data = df.tail(days)\n\n    fig, ax = plt.subplots(figsize=(20, 10))\n\n    # Calculate the distance between points for width of candlesticks\n    width = 0.6\n\n    # Create candlestick colors\n    up = data[data.close >= data.open]\n    down = data[data.close < data.open]\n\n    # Plot candlesticks\n    ax.bar(up.index, up.close-up.open, width, bottom=up.open, color='green', alpha=0.5)\n    ax.bar(down.index, down.close-down.open, width, bottom=down.open, color='red', alpha=0.5)\n\n    # Plot high-low lines\n    ax.vlines(up.index, up.low, up.high, color='green', linewidth=1)\n    ax.vlines(down.index, down.low, down.high, color='red', linewidth=1)\n\n    plt.title(f'Tesla Stock - Candlestick Chart (Last {days} Trading Days)')\n    plt.ylabel('Price ($)')\n    plt.grid(True)\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\ndef compare_model_metrics(metrics_lstm, metrics_rnn):\n    \"\"\"Compare model metrics side by side\"\"\"\n    metrics = pd.DataFrame({\n        'LSTM': metrics_lstm,\n        'RNN': metrics_rnn\n    })\n\n    plt.figure(figsize=(12, 8))\n\n    # Plot the metrics as a bar chart\n    ax = metrics.plot(kind='bar', color=['blue', 'green'], alpha=0.7)\n\n    # Add value labels on top of bars\n    for container in ax.containers:\n        ax.bar_label(container, fmt='%.4f')\n\n    plt.title('Model Performance Metrics: LSTM vs RNN')\n    plt.ylabel('Value')\n    plt.xlabel('Metric')\n    plt.grid(axis='y')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n    # Print the metrics table\n    print(\"\\n--- Model Performance Comparison ---\")\n    print(metrics)\n\n    # Calculate improvement percentages\n    improvement = ((metrics['RNN'] - metrics['LSTM']) / metrics['RNN'] * 100).abs()\n    better_model = ['LSTM' if metrics['LSTM'][i] < metrics['RNN'][i] else 'RNN' for i in range(len(metrics))]\n\n    # For R², higher is better\n    if 'R²' in metrics.index:\n        idx = metrics.index.get_loc('R²')\n        better_model[idx] = 'LSTM' if metrics['LSTM'][idx] > metrics['RNN'][idx] else 'RNN'\n\n    comparison = pd.DataFrame({\n        'LSTM': metrics['LSTM'],\n        'RNN': metrics['RNN'],\n        'Improvement (%)': improvement,\n        'Better Model': better_model\n    })\n\n    print(\"\\n--- Detailed Comparison ---\")\n    print(comparison)\n\n\ndef plot_stock_with_ma_rsi(df, ma, n_steps, rsi):\n    \"\"\"Plot stock price with moving average, volume and RSI\"\"\"\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 12), gridspec_kw={'height_ratios': [3, 1]})\n    \n    # Top plot: Price, Volume, and MA\n    ax1.plot(df.index, df['close'], 'b-', label='Close Price')\n    ax1.bar(df.index, df['volume']/3e6, alpha=0.3, label='Volume (scaled)')\n    ax1.plot(df.index[n_steps:], ma[n_steps:], 'r', label=f'{n_steps}-day Moving Avg')\n    ax1.set_ylabel(\"Price ($)\")\n    ax1.set_title(\"Tesla Stock Price with Moving Average, Volume, and RSI\")\n    ax1.legend(loc='upper left')\n    ax1.grid(True)\n    \n    # Bottom plot: RSI\n    ax2.plot(df.index, rsi, 'g-', label='RSI')\n    ax2.axhline(y=70, color='r', linestyle='--', alpha=0.5)\n    ax2.axhline(y=30, color='g', linestyle='--', alpha=0.5)\n    ax2.set_ylim(0, 100)\n    ax2.fill_between(df.index, rsi, 70, where=(rsi>=70), color='r', alpha=0.3)\n    ax2.fill_between(df.index, rsi, 30, where=(rsi<=30), color='g', alpha=0.3)\n    ax2.set_ylabel(\"RSI\")\n    ax2.set_xlabel(\"Date\")\n    ax2.grid(True)\n    ax2.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n","metadata":{"id":"oPj7sSqCH2Ja","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:38.912734Z","iopub.execute_input":"2025-04-26T17:17:38.912974Z","iopub.status.idle":"2025-04-26T17:17:38.952274Z","shell.execute_reply.started":"2025-04-26T17:17:38.912958Z","shell.execute_reply":"2025-04-26T17:17:38.951650Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Results and Analysis\n\nThe analysis compares LSTM and RNN models based on:\n\n1. **Training Performance**:\n   - Training time\n   - Training and validation loss curves\n   - Convergence behavior\n\n2. **Prediction Accuracy**:\n   - Test set prediction errors\n   - Performance on various metrics (MSE, RMSE, MAE, R², MAPE)\n   - Error distribution analysis\n\n3. **Forecasting**:\n   - 30-day price forecasts\n   - Forecast divergence between models\n   - Percentage change from last known price\n\nThe results help determine which architecture is better suited for Tesla stock price prediction and whether the additional complexity of LSTM provides meaningful improvements over simple RNN.","metadata":{"execution":{"iopub.status.busy":"2025-04-26T14:08:36.866113Z","iopub.execute_input":"2025-04-26T14:08:36.866803Z","iopub.status.idle":"2025-04-26T14:08:36.875179Z","shell.execute_reply.started":"2025-04-26T14:08:36.866775Z","shell.execute_reply":"2025-04-26T14:08:36.874228Z"}}},{"cell_type":"code","source":"# -------------- Main Execution --------------\ndef main():\n    # Configuration parameters\n    set_seeds(seed)\n    file_path = \"/kaggle/input/tesla-stock-price-data-2000-2025/tesla_stock_data_2000_2025.csv\"\n    seq_length = 180\n    units = 20\n    batch_size = 32\n    epochs = 25\n    days_to_predict = 30\n    test_size = 0.15\n    validation_size = 0.15  \n    n_steps_ma = 10\n\n    # Load data\n    df = load_data(file_path)\n    print(\"Data loaded successfully!\")\n    print(f\"Dataset shape: {df.shape}\")\n    print(df.head())\n\n    # Data exploration and visualization\n    print(\"\\n--- Data Statistics ---\")\n    print(df.drop(['date'], axis=1, errors='ignore').describe())\n\n    # Calculate and plot percentage change\n    pct_change = calculate_pct_change(df)\n    plot_percentage_change(df.index, pct_change)\n\n    # Calculate RSI\n    rsi = calculate_rsi(df['close'], window=14)\n\n    # Calculate and plot moving average\n    ma = calculate_moving_average(df['close'], n_steps=n_steps_ma)\n    # plot_stock_with_ma(df, ma, n_steps_ma)\n    # Plot stock with MA and RSI\n    plot_stock_with_ma_rsi(df, ma, n_steps_ma, rsi)\n\n    # Additional visualizations\n    plot_volatility_analysis(df)\n    plot_candlestick_chart(df, days=90)\n\n    # Data preparation for model\n    scaler = MinMaxScaler()\n    # df = df.iloc[1700:, :]\n    data = scaler.fit_transform(df.iloc[:, :-1].values)\n\n    # Create sequences\n    X, y = create_sequences(data, seq_length)\n    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n\n    # Split into train, validation, and test sets\n    # First, determine indices for splitting\n    test_split_index = X.shape[0] - int(np.round(X.shape[0] * test_size))\n    val_split_index = test_split_index - int(np.round(X.shape[0] * validation_size))\n\n    # Training set\n    X_train = X[:val_split_index, :, :]\n    y_train = y[:val_split_index, :]\n\n    # Validation set\n    X_val = X[val_split_index:test_split_index, :, :]\n    y_val = y[val_split_index:test_split_index, :]\n\n    # Test set\n    X_test = X[test_split_index:, :, :]\n    y_test = y[test_split_index:, :]\n\n    print(f\"Train shapes: X={X_train.shape}, y={y_train.shape}\")\n    print(f\"Validation shapes: X={X_val.shape}, y={y_val.shape}\")\n    print(f\"Test shapes: X={X_test.shape}, y={y_test.shape}\")\n\n    # Build models\n    lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]), units)\n    lstm_model.summary()\n\n    rnn_model = build_rnn_model((X_train.shape[1], X_train.shape[2]), units)\n    rnn_model.summary()\n\n    # Dictionary to store training times\n    training_times = {}\n\n    # Check if GPU is available\n    if tf.config.list_physical_devices('GPU'):\n        print(\"Using GPU for training\")\n        device = '/GPU:0'\n    else:\n        print(\"Using CPU for training\")\n        device = '/CPU:0'\n\n    set_seeds(seed)\n    # Train LSTM model with validation data and measure time\n    with tf.device(device):\n        print(\"\\n--- Training LSTM Model ---\")\n        start_time = time.time()\n        lstm_history = lstm_model.fit(\n            X_train, y_train,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_data=(X_val, y_val),  # Added validation data\n            verbose=1\n        )\n        end_time = time.time()\n        training_times['LSTM'] = end_time - start_time\n        print(f\"LSTM training time: {training_times['LSTM']:.2f} seconds\")\n\n        # Train RNN model with validation data and measure time\n        set_seeds(seed)\n        print(\"\\n--- Training RNN Model ---\")\n        start_time = time.time()\n        rnn_history = rnn_model.fit(\n            X_train, y_train,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_data=(X_val, y_val),  # Added validation data\n            verbose=1\n        )\n        end_time = time.time()\n        training_times['RNN'] = end_time - start_time\n        print(f\"RNN training time: {training_times['RNN']:.2f} seconds\")\n\n    # Plot training history comparison with validation losses\n    plot_training_history(lstm_history, rnn_history)\n    plot_individual_training_history(lstm_history, rnn_history)\n\n    # Make predictions with both models\n    lstm_pred_scaled = lstm_model.predict(X_test)\n    lstm_pred = scaler.inverse_transform(lstm_pred_scaled)\n\n    rnn_pred_scaled = rnn_model.predict(X_test)\n    rnn_pred = scaler.inverse_transform(rnn_pred_scaled)\n\n    # Ground truth (actual values)\n    actual = scaler.inverse_transform(y_test)\n\n    # Create DataFrames for predictions\n    lstm_pred_df = pd.DataFrame(lstm_pred, columns=df.columns[:-1])\n    lstm_pred_df.index = df.index[seq_length + test_split_index:]\n\n    rnn_pred_df = pd.DataFrame(rnn_pred, columns=df.columns[:-1])\n    rnn_pred_df.index = df.index[seq_length + test_split_index:]\n\n    # Calculate and compare performance metrics\n    lstm_metrics = calculate_metrics(actual[:, 0], lstm_pred[:, 0])  # Using only 'close' column\n    rnn_metrics = calculate_metrics(actual[:, 0], rnn_pred[:, 0])    # Using only 'close' column\n\n    compare_model_metrics(lstm_metrics, rnn_metrics)\n\n    # Plot prediction comparisons\n    plot_model_comparison(df, lstm_pred_df, rnn_pred_df)\n    plot_error_comparison(df, lstm_pred_df, rnn_pred_df)\n    plot_close_predictions_detail(df, lstm_pred_df, rnn_pred_df, window_size=30)\n\n    # Generate forecasts with both models\n    last_sequence = scaler.transform(lstm_pred_df.values[-seq_length:])\n    future_start_date = '2025/3/4'\n\n    print(\"\\n--- Generating Forecasts ---\")\n    lstm_forecast = forecast_future(\n        lstm_model,\n        last_sequence,\n        scaler,\n        days_to_predict,\n        seq_length,\n        X_train.shape[2],\n        future_start_date\n    )\n    lstm_forecast.columns = df.columns[:-1]\n\n    rnn_forecast = forecast_future(\n        rnn_model,\n        last_sequence,\n        scaler,\n        days_to_predict,\n        seq_length,\n        X_train.shape[2],\n        future_start_date\n    )\n    rnn_forecast.columns = df.columns[:-1]\n\n    # Plot forecasts comparison\n    plot_model_comparison(df, lstm_pred_df, rnn_pred_df, lstm_forecast, rnn_forecast)\n    plot_forecast_comparison(lstm_forecast, rnn_forecast)\n\n    # Print forecast results\n    print(\"\\n--- LSTM Forecast Results ---\")\n    print(lstm_forecast[['open', 'close']].head())\n    print(f\"LSTM forecast ending price: ${lstm_forecast['close'].iloc[-1]:.2f}\")\n    lstm_forecast_change = (lstm_forecast['close'].iloc[-1] - df['close'].iloc[-1]) / df['close'].iloc[-1] * 100\n    print(f\"LSTM percentage change from last known price: {lstm_forecast_change:.2f}%\")\n\n    print(\"\\n--- RNN Forecast Results ---\")\n    print(rnn_forecast[['open', 'close']].head())\n    print(f\"RNN forecast ending price: ${rnn_forecast['close'].iloc[-1]:.2f}\")\n    rnn_forecast_change = (rnn_forecast['close'].iloc[-1] - df['close'].iloc[-1]) / df['close'].iloc[-1] * 100\n    print(f\"RNN percentage change from last known price: {rnn_forecast_change:.2f}%\")\n\n    # Final comparison summary\n    print(\"\\n--- Model Comparison Summary ---\")\n    print(f\"LSTM training time: {training_times['LSTM']:.2f} seconds\")\n    print(f\"RNN training time: {training_times['RNN']:.2f} seconds\")\n    print(f\"Training time difference: {(training_times['LSTM'] - training_times['RNN']):.2f} seconds\")\n\n    # Validation performance\n    lstm_val_loss = lstm_history.history['val_loss'][-1]\n    rnn_val_loss = rnn_history.history['val_loss'][-1]\n    print(f\"Final LSTM validation loss: {lstm_val_loss:.6f}\")\n    print(f\"Final RNN validation loss: {rnn_val_loss:.6f}\")\n    print(f\"Validation loss difference: {(lstm_val_loss - rnn_val_loss):.6f}\")\n\n    forecast_diff = (lstm_forecast['close'].iloc[-1] - rnn_forecast['close'].iloc[-1])\n    forecast_diff_pct = (forecast_diff / rnn_forecast['close'].iloc[-1]) * 100\n    print(f\"Final forecast difference: ${forecast_diff:.2f} ({forecast_diff_pct:.2f}%)\")\n\n    # Determine which model performed better overall\n    mse_better = \"LSTM\" if lstm_metrics[\"MSE\"] < rnn_metrics[\"MSE\"] else \"RNN\"\n    r2_better = \"LSTM\" if lstm_metrics[\"R²\"] > rnn_metrics[\"R²\"] else \"RNN\"\n    val_better = \"LSTM\" if lstm_val_loss < rnn_val_loss else \"RNN\"\n\n    print(f\"Based on MSE, {mse_better} performed better\")\n    print(f\"Based on R², {r2_better} performed better\")\n    print(f\"Based on validation loss, {val_better} performed better\")\n\n    print(\"\\nAnalysis complete\")","metadata":{"id":"JsLVgIDxJA4Q","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:38.953318Z","iopub.execute_input":"2025-04-26T17:17:38.953566Z","iopub.status.idle":"2025-04-26T17:17:38.975572Z","shell.execute_reply.started":"2025-04-26T17:17:38.953541Z","shell.execute_reply":"2025-04-26T17:17:38.974820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if  __name__ == \"__main__\":\n  set_seeds(seed)\n  main()","metadata":{"id":"Q2l3w_4GJaeP","outputId":"5e14d5d0-798c-44b0-98db-fe9dcc97cd63","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:17:38.976335Z","iopub.execute_input":"2025-04-26T17:17:38.976666Z","iopub.status.idle":"2025-04-26T17:18:42.645496Z","shell.execute_reply.started":"2025-04-26T17:17:38.976647Z","shell.execute_reply":"2025-04-26T17:18:42.644746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nThis analysis demonstrates the application of recurrent neural networks to financial time series forecasting, specifically comparing LSTM and RNN architectures.\n\nKey findings:\n- LSTM vs RNN performance differences in terms of accuracy and training time\n- The impact of model architecture on forecasting quality\n- The challenges of multi-step recursive forecasting\n\nLimitations and future work:\n- Incorporating additional features (technical indicators, market sentiment)\n- Testing more advanced architectures (Transformer models, attention mechanisms)\n- Ensemble methods to combine multiple forecasts\n- Hyperparameter optimization\n- Exploring longer forecast horizons and their reliability","metadata":{}},{"cell_type":"markdown","source":"## Configuration Parameters\n\nThe analysis uses the following configuration parameters:\n\n- **seq_length = 180**: Number of days in each input sequence\n- **units = 20**: Number of neurons in the recurrent layers\n- **batch_size = 32**: Number of samples per gradient update\n- **epochs = 25**: Number of complete passes through the training dataset\n- **days_to_predict = 30**: Forecast horizon in days\n- **test_size = 0.15**: Proportion of data used for testing\n- **validation_size = 0.15**: Proportion of data used for validation\n- **n_steps_ma = 10**: Window size for moving average calculation\n\nThese parameters can be adjusted to experiment with different model configurations.","metadata":{}}]}